# Проект TF-IDF.
***
Задание: Реализовать веб-приложение. В качестве интерфейса сделать страницу с формой для загрузки текстового файла, после загрузки и обработки файла отображается таблица с 50 словами с колонками:
слово, 
tf - сколько раз это слово встречается в тексте, 
idf - обратная частота документа. 
Вывод упорядочить по уменьшению idf.
***
## Версия.
***
1.3.0
***
## Примечания.
***
Для подсчета TF в тексте оставляются только слова определенной длины (для игнорирования предлогов).
Этот параметр можно настроить в файле .env - параметр ANALYZER_MIN_WORD_LENGTH.  
***
## Отзыв от гостя
***
### Замечания
  1. Не хватает конкретного примера .env файла, где осталось бы просто заполнить пару полей
  2. На моей машине пришлось корректировать docker-compose файл для того, чтобы запустить, возможно в readme не совсем актуальная инфа по запуску
### Крутые моменты
  1. Есть настройка min длины слова для расчетов
  2. Есть nginx и в целом все по настройкам очень серьезно
  3. Есть миграции и в целом инфра сделана здорово

     
Как видно в основном у меня жалобы на деплой, .env и ридми, в остальном все здорово
***
## Структура.
***
Проект состоит из 4 сервисов, упакованных в контейнеры.
* сервис бэкенд - основное приложение
* сервис БД
* сервис вэб сервера nginx
* сервис redis для кеширования
***
## Установка.
***
Клонировать репозиторий и перейти в него в командной строке.

```
git clone git@github.com:mvrogozov/tf-idf-django.git
```
Перейти в папку infra.
Создать файл .env и заполнить его необходимыми переменными окружения(см.ниже)
```
sudo docker compose up
```
Для выполнения миграций и сбора статики выполнить:
```
./migrate
```
Для создания суперпользователя выполнить:
```
docker exec -it backend-tfidf bash
```
```
python manage.py createsuperuser
```
Переменные окружения, необходимые для запуска:

* DB_HOST - имя хоста с БД
* POSTGRES_DB - имя БД
* DB_PORT - порт для БД
* POSTGRES_PASSWORD - пароль БД
* POSTGRES_USER - пользователь БД
* DJANGO_SECRET_KEY - секретный ключ для django
* ALLOWED_HOSTS - хосты для контейнера django
* HTTP_PORT - порт приложения

Переменные с настройками приложения:

* ANALYZER_MIN_WORD_LENGTH - минимальная длина слова для статистики
* ANALYZER_WORDS_LIMIT - количество наиболее редких слов для вывода 
статистики в API
* ANALYZER_USE_NORMALIZE - (True/False) включить/отключить нормализацию
слов при анализе документов
***
## Документация openapi

* YOUR-BASE-URL/api/schema/
* [schema.yml](schema.yml)

***
## Схема БД
***
[db_diagram.png](db_diagram.png)
***
## Генерация клиента для python
Для генерации клиента необходимо установить open-api-client командой 
```
pip install openapi-python-client
``` 
в теминале bash.
После этого сгенерировать клиент командой 
```
openapi-python-client generate --path PATH-TO-SCHEMA/schema.yml
```
Получим папку с клиентом. Описание работы с ним доступно в этой папке в файле README.md. 
Пример файла с запросом: [client_example.py](client_example.py)
***
## Changelog
***
### 1.0.0
Добавлено:
* rest api
* эндпоинты status, version, metrics
* настройки портов приложения, допустимых хостов для django

Изменено:
* настройки для nginx

### 1.0.1
Добавлено:
* эндпоинты с документацией (swagger и redoc)

### 1.1.0
Добавлено:
* авторизация пользователей через JWT токен
* модель коллекции
* эндпоинты для коллекций, документов и пользователей
* возможность генерации клиента для python

Изменено:
* модель пользователя
* модель документа

### 1.2.0

Добавлено:
* эндпоинты для кодирования и декодирования текста в код Хаффмана
* вынесена в переменные окружения возможность отключения нормализации
слов для подсчета статистики 

### 1.3.0

Добавлено:
* кеширование в redis

Изменено:
* настройки заголовков кеширования в nginx

### 1.3.1

Добавлено:
* проверка прав для POST запросов

### 1.3.2

Добавлено:
* проверка формата загружаемого файла
***
Автор:
* Рогозов Михаил
